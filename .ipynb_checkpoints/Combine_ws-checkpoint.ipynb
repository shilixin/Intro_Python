{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Combining Multiple Excel Sheets of A Workbook Into One Sheet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpouse of this little python codes is to combine/merge all the worksheets from one Excel file and export the result to another Excel file for our scripts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is a powerful multi-purpose programming language created by Guido van Rossum.\n",
    "\n",
    "It has simple easy-to-use syntax, making it the perfect language for someone trying to learn computer programming for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install WordCloud\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more information on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "pip install WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-87015b686e8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpPlot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\lixinshi\\\\Combine\\\\Input\\\\Hierarchy.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as pPlot\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import numpy as npy\n",
    "import matplotlib.pyplot as plt\n",
    "dataset = open(\"C:\\\\Users\\\\lixinshi\\\\Combine\\\\Input\\\\Hierarchy.txt\", \"r\").read()\n",
    "wordcloud = WordCloud().generate(dataset)\n",
    "plt.imshow(wordcloud)\n",
    "\n",
    "# Turn off the axis. Otherwise you will see a bunch of extra numbers around the word cloud\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Show the word cloud\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()  #  Will import Seaborn functionalities\n",
    "# we don't like warnings\n",
    "# you can comment the following 2 lines if you'd like to\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT-RIB-102721_01\n",
      "22\n",
      "The number of worksheet from Excel file:  22\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd as xd\n",
    "# import numpy as np\n",
    "# from os.path  import basename\n",
    "from pandas import DataFrame\n",
    "\n",
    "df = []\n",
    "f = pd.ExcelFile(\"C:\\\\Users\\\\lixinshi\\\\Combine\\\\Input\\\\Test_files.xlsx\")\n",
    "result = pd.ExcelFile(\"C:\\\\Users\\\\lixinshi\\\\Combine\\\\Output\\\\Master_files.xlsx\")\n",
    "print(f.sheet_names[0])\n",
    "print(len(f.sheet_names))\n",
    "print(\"The number of worksheet from Excel file: \", len(f.sheet_names))\n",
    "numberOfSheets = len(f.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows of Data = 208\n",
      "Number of Columns of Data = 61"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import sys\n",
    "#read data from uci data repository\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\")\n",
    "data = urllib.request.urlopen(target_url)\n",
    "#arrange data into list for labels and list of lists for attributes\n",
    "xList = []\n",
    "labels = []\n",
    "for line in data:\n",
    " #split on comma\n",
    " row = line.decode('utf8').strip().split(',')\n",
    " xList.append(row)\n",
    "sys.stdout.write(\"Number of Rows of Data = \" + str(len(xList)) + '\\n')\n",
    "sys.stdout.write(\"Number of Columns of Data = \" + str(len(xList[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lixinshi'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roadmap for Building Machine Learning Models\n",
    "\n",
    "# 1. Prepare Problem\n",
    "# a) Define The Business Objective\n",
    "# b) Select the datasets\n",
    "# c) Load dataset\n",
    "# d) Load libraries\n",
    "\n",
    "\n",
    "# Data Pre-processing\n",
    "# This is the first step in building a machine learning model. Data pre-processing refers to the transformation of data\n",
    "# before feeding it into the model. It deals with the techniques that are used to convert unusable raw data into clean \n",
    "# reliable data.\n",
    "\n",
    "# Since data collection is often not performed in a controlled manner, raw data often contains outliers \n",
    "# (for example, age = 120), nonsensical data combinations (for example, model: bicycle, type: 4-wheeler), missing values, \n",
    "# scale problems, and so on. Because of this, raw data cannot be fed into a machine learning model because it might \n",
    "# compromise the quality of the results. As such, this is the most important step in the process of data science.\n",
    "\n",
    "\n",
    "# 2. Summarize Data\n",
    "# a) Descriptive statistics\n",
    "# b) Data visualizations\n",
    "\n",
    "# 3. Prepare Data\n",
    "# a) Data Cleaning\n",
    "# b) Feature Selection\n",
    "# c) Data Transformation\n",
    "\n",
    "# Model Learning\n",
    "# After pre-processing the data and splitting it into train/test sets (more on this later), we move on to modeling. Models \n",
    "# are nothing but sets of well-defined methods called algorithms that use pre-processed data to learn patterns, which can \n",
    "# later be used to make predictions. There are different types of learning algorithms, including supervised, semi-supervised, \n",
    "# unsupervised, and reinforcement learning. These will be discussed later.\n",
    "\n",
    "# 4. Modeling Strategy\n",
    "# a) Select Suitable Algorithms\n",
    "# b) Select Training/Testing Approaches\n",
    "# c) Train \n",
    "\n",
    "\n",
    "# Model Evaluation\n",
    "# In this stage, the models are evaluated with the help of specific performance metrics. With these metrics, we can go on to \n",
    "# tune the hyperparameters of a model in order to improve it. This process is called hyperparameter optimization. We will \n",
    "# repeat this step until we are satisfied with the performance.\n",
    "\n",
    "# 4. Evaluate Algorithms\n",
    "# a) Split-out validation dataset\n",
    "# b) Test options and evaluation metric\n",
    "# c) Spot Check Algorithms\n",
    "# d) Compare Algorithms\n",
    "\n",
    "# Prediction\n",
    "# Once we are happy with the results from the evaluation step, we will then move on to predictions. Predictions are made \n",
    "# by the trained model when it is exposed to a new dataset. In a business setting, these predictions can be shared with \n",
    "# decision makers to make effective business choices.\n",
    "\n",
    "# 5. Improve Accuracy\n",
    "# a) Algorithm Tuning\n",
    "# b) Ensembles\n",
    "\n",
    "# Model Deployment\n",
    "# The whole process of machine learning does not just stop with model building and prediction. It also involves making use \n",
    "# of the model to build an application with the new data. Depending on the business requirements, the deployment may be a \n",
    "# report, or it may be some repetitive data science steps that are to be executed. After deployment, a model needs proper \n",
    "# management and maintenance at regular intervals to keep it up and running.\n",
    "\n",
    "# 6. Finalize Model\n",
    "# a) Predictions on validation dataset\n",
    "# b) Create standalone model on entire training dataset\n",
    "# c) Save model for later use\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
